{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2f8f6a",
   "metadata": {},
   "source": [
    "Roshan Gautam\n",
    "DataMining Lab 5\n",
    "University of Cumberlands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8f6fe",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, homogeneity_score, completeness_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting parameters\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "## Step 1: Data Preparation and Exploration\n",
    "\n",
    "print(\"=== STEP 1: DATA PREPARATION AND EXPLORATION ===\\n\")\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "X = wine_data.data\n",
    "y = wine_data.target\n",
    "\n",
    "# Create DataFrame for easier handling\n",
    "df = pd.DataFrame(X, columns=wine_data.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Features: {len(wine_data.feature_names)}\")\n",
    "print(f\"Classes: {len(np.unique(y))}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")\n",
    "\n",
    "print(\"\\nDataset Structure:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"\\nFeatures standardized for clustering analysis.\")\n",
    "\n",
    "## Step 2: Hierarchical Clustering\n",
    "\n",
    "print(\"\\n=== STEP 2: HIERARCHICAL CLUSTERING ===\\n\")\n",
    "\n",
    "# Test different numbers of clusters\n",
    "n_clusters_range = [2, 3, 4, 5]\n",
    "hierarchical_results = {}\n",
    "\n",
    "for n_clusters in n_clusters_range:\n",
    "    # Apply Agglomerative Clustering\n",
    "    hierarchical = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "    cluster_labels = hierarchical.fit_predict(X_scaled)\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    sil_score = silhouette_score(X_scaled, cluster_labels)\n",
    "    \n",
    "    hierarchical_results[n_clusters] = {\n",
    "        'labels': cluster_labels,\n",
    "        'silhouette_score': sil_score\n",
    "    }\n",
    "    \n",
    "    print(f\"n_clusters={n_clusters}: Silhouette Score = {sil_score:.3f}\")\n",
    "\n",
    "# Find optimal number of clusters\n",
    "best_n_clusters = max(hierarchical_results.keys(), \n",
    "                     key=lambda k: hierarchical_results[k]['silhouette_score'])\n",
    "print(f\"\\nBest n_clusters for Hierarchical: {best_n_clusters}\")\n",
    "\n",
    "# Use best configuration for visualization\n",
    "best_hierarchical_labels = hierarchical_results[best_n_clusters]['labels']\n",
    "\n",
    "# Visualize clusters using first two principal components\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=best_hierarchical_labels, cmap='viridis')\n",
    "plt.title(f'Hierarchical Clustering (n_clusters={best_n_clusters})')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis')\n",
    "plt.title('True Labels')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.colorbar()\n",
    "\n",
    "# Generate and plot dendrogram\n",
    "plt.subplot(1, 3, 3)\n",
    "linkage_matrix = linkage(X_scaled, method='ward')\n",
    "dendro = dendrogram(linkage_matrix, truncate_mode='level', p=5)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Distance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## Step 3: DBSCAN Clustering\n",
    "\n",
    "print(\"\\n=== STEP 3: DBSCAN CLUSTERING ===\\n\")\n",
    "\n",
    "# Test different parameter combinations\n",
    "eps_values = [0.5, 1.0, 1.5, 2.0]\n",
    "min_samples_values = [3, 5, 7, 10]\n",
    "\n",
    "dbscan_results = {}\n",
    "best_dbscan_score = -1\n",
    "best_dbscan_params = None\n",
    "\n",
    "print(\"Testing DBSCAN parameters:\")\n",
    "print(\"eps\\tmin_samples\\tn_clusters\\tn_noise\\tsilhouette\")\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        # Apply DBSCAN\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        cluster_labels = dbscan.fit_predict(X_scaled)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "        n_noise = list(cluster_labels).count(-1)\n",
    "        \n",
    "        if n_clusters > 1:\n",
    "            sil_score = silhouette_score(X_scaled, cluster_labels)\n",
    "            homogeneity = homogeneity_score(y, cluster_labels)\n",
    "            completeness = completeness_score(y, cluster_labels)\n",
    "            \n",
    "            dbscan_results[(eps, min_samples)] = {\n",
    "                'labels': cluster_labels,\n",
    "                'n_clusters': n_clusters,\n",
    "                'n_noise': n_noise,\n",
    "                'silhouette_score': sil_score,\n",
    "                'homogeneity_score': homogeneity,\n",
    "                'completeness_score': completeness\n",
    "            }\n",
    "            \n",
    "            print(f\"{eps}\\t{min_samples}\\t\\t{n_clusters}\\t\\t{n_noise}\\t{sil_score:.3f}\")\n",
    "            \n",
    "            if sil_score > best_dbscan_score:\n",
    "                best_dbscan_score = sil_score\n",
    "                best_dbscan_params = (eps, min_samples)\n",
    "        else:\n",
    "            print(f\"{eps}\\t{min_samples}\\t\\t{n_clusters}\\t\\t{n_noise}\\tN/A\")\n",
    "\n",
    "if best_dbscan_params:\n",
    "    print(f\"\\nBest DBSCAN parameters: eps={best_dbscan_params[0]}, min_samples={best_dbscan_params[1]}\")\n",
    "    \n",
    "    best_dbscan_result = dbscan_results[best_dbscan_params]\n",
    "    best_dbscan_labels = best_dbscan_result['labels']\n",
    "    \n",
    "    # Print detailed metrics for best configuration\n",
    "    print(\"\\nBest DBSCAN Results:\")\n",
    "    print(f\"Number of clusters: {best_dbscan_result['n_clusters']}\")\n",
    "    print(f\"Number of noise points: {best_dbscan_result['n_noise']}\")\n",
    "    print(f\"Silhouette Score: {best_dbscan_result['silhouette_score']:.3f}\")\n",
    "    print(f\"Homogeneity Score: {best_dbscan_result['homogeneity_score']:.3f}\")\n",
    "    print(f\"Completeness Score: {best_dbscan_result['completeness_score']:.3f}\")\n",
    "    \n",
    "    # Visualize DBSCAN results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=best_dbscan_labels, cmap='viridis')\n",
    "    plt.title(f'DBSCAN (eps={best_dbscan_params[0]}, min_samples={best_dbscan_params[1]})')\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "    plt.colorbar(scatter)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    # Highlight noise points\n",
    "    noise_mask = best_dbscan_labels == -1\n",
    "    plt.scatter(X_pca[~noise_mask, 0], X_pca[~noise_mask, 1], \n",
    "               c=best_dbscan_labels[~noise_mask], cmap='viridis', alpha=0.7, label='Clusters')\n",
    "    plt.scatter(X_pca[noise_mask, 0], X_pca[noise_mask, 1], \n",
    "               c='red', marker='x', s=50, label='Noise')\n",
    "    plt.title('DBSCAN with Noise Points Highlighted')\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis')\n",
    "    plt.title('True Labels')\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "## Step 4: Analysis and Insights\n",
    "\n",
    "print(\"\\n=== STEP 4: ANALYSIS AND INSIGHTS ===\\n\")\n",
    "\n",
    "print(\"COMPARISON BETWEEN HIERARCHICAL AND DBSCAN CLUSTERING:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if best_dbscan_params:\n",
    "    # Compare the best results\n",
    "    hier_sil = hierarchical_results[best_n_clusters]['silhouette_score']\n",
    "    dbscan_sil = best_dbscan_result['silhouette_score']\n",
    "    \n",
    "    print(f\"Hierarchical Clustering (n_clusters={best_n_clusters}):\")\n",
    "    print(f\"  - Silhouette Score: {hier_sil:.3f}\")\n",
    "    print(f\"  - Number of clusters: {best_n_clusters}\")\n",
    "    print(f\"  - All points assigned to clusters\")\n",
    "    \n",
    "    print(f\"\\nDBSCAN (eps={best_dbscan_params[0]}, min_samples={best_dbscan_params[1]}):\")\n",
    "    print(f\"  - Silhouette Score: {dbscan_sil:.3f}\")\n",
    "    print(f\"  - Number of clusters: {best_dbscan_result['n_clusters']}\")\n",
    "    print(f\"  - Noise points: {best_dbscan_result['n_noise']}\")\n",
    "    print(f\"  - Homogeneity Score: {best_dbscan_result['homogeneity_score']:.3f}\")\n",
    "    print(f\"  - Completeness Score: {best_dbscan_result['completeness_score']:.3f}\")\n",
    "\n",
    "print(\"\\nPARAMETER INFLUENCE:\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Hierarchical Clustering:\")\n",
    "print(\"- Number of clusters directly controls the granularity of clustering\")\n",
    "print(\"- Ward linkage minimizes within-cluster variance\")\n",
    "print(\"- Always produces exactly n_clusters, regardless of data structure\")\n",
    "\n",
    "print(\"\\nDBSCAN:\")\n",
    "print(\"- eps controls the neighborhood size for core points\")\n",
    "print(\"- min_samples determines minimum density for cluster formation\")\n",
    "print(\"- Can identify noise points and handles clusters of varying density\")\n",
    "print(\"- Number of clusters emerges from the data structure\")\n",
    "\n",
    "print(\"\\nSTRENGTHS AND WEAKNESSES:\")\n",
    "print(\"-\" * 25)\n",
    "print(\"Hierarchical Clustering:\")\n",
    "print(\"Strengths:\")\n",
    "print(\"  + Deterministic results\")\n",
    "print(\"  + Provides hierarchical structure via dendrogram\")\n",
    "print(\"  + Works well with compact, well-separated clusters\")\n",
    "print(\"  + No noise points - all data assigned\")\n",
    "print(\"Weaknesses:\")\n",
    "print(\"  - Requires pre-specifying number of clusters\")\n",
    "print(\"  - Sensitive to outliers\")\n",
    "print(\"  - Assumes spherical clusters\")\n",
    "\n",
    "print(\"\\nDBSCAN:\")\n",
    "print(\"Strengths:\")\n",
    "print(\"  + Automatically determines number of clusters\")\n",
    "print(\"  + Robust to outliers (identifies as noise)\")\n",
    "print(\"  + Can find arbitrarily shaped clusters\")\n",
    "print(\"  + No assumption about cluster shape\")\n",
    "print(\"Weaknesses:\")\n",
    "print(\"  - Sensitive to parameter selection\")\n",
    "print(\"  - Struggles with varying densities\")\n",
    "print(\"  - May not work well with high-dimensional data\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nSUMMARY:\")\n",
    "print(f\"- Wine dataset has {X.shape[0]} samples with {X.shape[1]} features\")\n",
    "print(f\"- True number of wine classes: {len(np.unique(y))}\")\n",
    "print(f\"- Best Hierarchical clustering found {best_n_clusters} clusters\")\n",
    "if best_dbscan_params:\n",
    "    print(f\"- Best DBSCAN found {best_dbscan_result['n_clusters']} clusters with {best_dbscan_result['n_noise']} noise points\")\n",
    "    if hier_sil > dbscan_sil:\n",
    "        print(f\"- Hierarchical clustering achieved better silhouette score ({hier_sil:.3f} vs {dbscan_sil:.3f})\")\n",
    "    else:\n",
    "        print(f\"- DBSCAN achieved better silhouette score ({dbscan_sil:.3f} vs {hier_sil:.3f})\")\n",
    "else:\n",
    "    print(\"- DBSCAN did not find suitable clustering with tested parameters\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
